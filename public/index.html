<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Card Capture Overlay</title>
  <meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1" />
  <style>
    /* --- Layout --- */
    html,body{margin:0;padding:0;background:#000;overflow:hidden;height:100%;}
    #videoElement{position:absolute;inset:0;width:100%;height:100%;object-fit:cover;transform:scaleX(-1);} /* Mirror for selfie-feel */
    #overlayCanvas{position:absolute;inset:0;pointer-events:none;}
    #statusText{position:absolute;top:8px;left:50%;transform:translateX(-50%);padding:4px 10px;border-radius:6px;font-size:16px;font-family:sans-serif;background:rgba(0,0,0,.6);color:#fff;}
    #captureButton{position:absolute;bottom:20px;left:50%;transform:translateX(-50%);padding:12px 26px;border:none;border-radius:24px;font-size:18px;font-weight:600;color:#000;background:rgba(255,255,255,.85);backdrop-filter:blur(4px);}
  </style>
</head>
<body>
  <video id="videoElement" autoplay playsinline></video>
  <canvas id="overlayCanvas"></canvas>
  <div id="statusText">Initializing…</div>
  <button id="captureButton" disabled>Capture</button>

<script src="https://docs.opencv.org/4.x/opencv.js"></script>
<script>
  const video = document.getElementById('videoElement');
  const canvas = document.getElementById('overlayCanvas');
  const ctx    = canvas.getContext('2d');
  const statusEl = document.getElementById('statusText');
  const captureBtn = document.getElementById('captureButton');

  // --- Camera setup ---
  async function setupCamera(){
    const stream = await navigator.mediaDevices.getUserMedia({video:{facingMode:'environment'},audio:false});
    video.srcObject = stream;
    return new Promise(res => video.onloadedmetadata = () => res());
  }

  // --- OpenCV ready flag ---
  let cvReady = false;
  cv['onRuntimeInitialized'] = () => {cvReady = true;};

  // --- Utility helpers ---
  function meanLuma(mat){
    const meanScalar = cv.mean(mat); // RGBA all equal in gray
    return meanScalar[0];            // just take first channel
  }

  function drawGrid(quad){
    // quad: 4 points ordered clockwise starting top-left
    const [p0,p1,p2,p3] = quad;
    const thirds = [1/3,2/3];
    thirds.forEach(t=>{
      // verticals from top to bottom edges
      const vx0 = p0.x + (p1.x-p0.x)*t;
      const vy0 = p0.y + (p1.y-p0.y)*t;
      const vx1 = p3.x + (p2.x-p3.x)*t;
      const vy1 = p3.y + (p2.y-p3.y)*t;
      ctx.moveTo(vx0,vy0); ctx.lineTo(vx1,vy1);
      // horizontals from left to right edges
      const hx0 = p0.x + (p3.x-p0.x)*t;
      const hy0 = p0.y + (p3.y-p0.y)*t;
      const hx1 = p1.x + (p2.x-p1.x)*t;
      const hy1 = p1.y + (p2.y-p1.y)*t;
      ctx.moveTo(hx0,hy0); ctx.lineTo(hx1,hy1);
    });
  }

  // --- Frame loop ---
  function processFrame(){
    if(!cvReady){return requestAnimationFrame(processFrame);}    
    const w = video.videoWidth;
    const h = video.videoHeight;
    if(!w||!h){return requestAnimationFrame(processFrame);}    
    canvas.width = w; canvas.height = h;

    // Draw current frame to canvas so we can read pixels
    ctx.drawImage(video,0,0,w,h);

    // Prepare OpenCV Mats
    let src = cv.imread(canvas);
    let gray = new cv.Mat();
    cv.cvtColor(src,gray,cv.COLOR_RGBA2GRAY);

    /*** Brightness check ***/
    const brightness = meanLuma(gray);
    const tooDark = brightness < 50; // tweak threshold (0-255)

    // Edge + contour detection only if bright enough
    let bestQuad = null;
    if(!tooDark){
      let blur = new cv.Mat();
      cv.GaussianBlur(gray,blur,new cv.Size(5,5),0);
      let edged = new cv.Mat();
      cv.Canny(blur,edged,60,160);
      let contours = new cv.MatVector();
      let hierarchy = new cv.Mat();
      cv.findContours(edged,contours,hierarchy,cv.RETR_LIST,cv.CHAIN_APPROX_SIMPLE);

      let maxArea = 0;
      for(let i=0;i<contours.size();i++){
        let cnt = contours.get(i);
        let peri = cv.arcLength(cnt,true);
        let approx = new cv.Mat();
        cv.approxPolyDP(cnt,approx,0.02*peri,true);
        if(approx.rows === 4){
          const area = cv.contourArea(approx);
          if(area > maxArea){
            maxArea = area;
            bestQuad = Array.from({length:4},(_,k)=>({x:approx.data32S[k*2],y:approx.data32S[k*2+1]}));
          }
        }
      }
      // cleanup
      blur.delete(); edged.delete(); contours.delete(); hierarchy.delete();
    }

    /*** Draw overlay ***/
    ctx.clearRect(0,0,w,h);

    if(tooDark){
      statusEl.textContent = 'Too dark – add light';
      statusEl.style.background = 'rgba(255,0,0,.7)';
      captureBtn.disabled = true;
    } else if(bestQuad && maxArea>(w*h*0.05)){
      statusEl.textContent = 'Hold steady & tap Capture';
      statusEl.style.background = 'rgba(0,0,0,.6)';
      // outline
      ctx.lineWidth = 4; ctx.strokeStyle = '#00FF00'; ctx.beginPath();
      ctx.moveTo(bestQuad[0].x,bestQuad[0].y);
      bestQuad.slice(1).forEach(p=>ctx.lineTo(p.x,p.y));
      ctx.closePath(); ctx.stroke();
      // grid
      ctx.lineWidth = 1.5; ctx.strokeStyle = 'rgba(0,255,0,.6)'; ctx.beginPath();
      drawGrid(bestQuad);
      ctx.stroke();
      captureBtn.disabled = false;
      captureBtn.onclick = ()=>saveImage(bestQuad);
    } else {
      statusEl.textContent = 'Align card in frame';
      statusEl.style.background = 'rgba(0,0,0,.6)';
      captureBtn.disabled = true;
    }

    // cleanup mats used every frame
    src.delete(); gray.delete();

    requestAnimationFrame(processFrame);
  }

  // --- Save snapshot (perspective-corrected) ---
  function saveImage(quad){
    /* Perspective correction */
    const w = 800, h = 500; // target resolution for saved card
    const srcTri = cv.matFromArray(4,1,cv.CV_32FC2,[
      quad[0].x,quad[0].y,
      quad[1].x,quad[1].y,
      quad[2].x,quad[2].y,
      quad[3].x,quad[3].y
    ]);
    const dstTri = cv.matFromArray(4,1,cv.CV_32FC2,[0,0,w,0,w,h,0,h]);
    const M = cv.getPerspectiveTransform(srcTri,dstTri);

    let src = cv.imread(canvas);
    let dst = new cv.Mat();
    const dsize = new cv.Size(w,h);
    cv.warpPerspective(src,dst,M,dsize,cv.INTER_LINEAR,cv.BORDER_CONSTANT,new cv.Scalar());
    cv.imshow(canvas,dst);

    const link = document.createElement('a');
    link.download = 'card.jpg';
    link.href = canvas.toDataURL('image/jpeg',0.9);
    link.click();

    // cleanup mats
    src.delete(); dst.delete(); M.delete(); srcTri.delete(); dstTri.delete();
  }

  (async()=>{
    try{
      await setupCamera();
      statusEl.textContent = 'Align card in frame';
      requestAnimationFrame(processFrame);
    }catch(err){
      statusEl.textContent = 'Camera access denied';
      console.error(err);
    }
  })();
</script>
</body>
</html>